# Debesium - Pipeline de Dados com Apache Kafka

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa um pipeline de dados usando **Apache Kafka** e **Debezium** para capturar mudanÃ§as (Change Data Capture - CDC) de um banco de dados **MongoDB** e sincronizÃ¡-las com um banco **PostgreSQL**. O sistema utiliza a arquitetura de conectores Kafka para garantir uma sincronizaÃ§Ã£o em tempo real entre os bancos de dados.

## ğŸ—ï¸ Arquitetura

```
MongoDB â†’ Debezium Connector â†’ Apache Kafka â†’ JDBC Sink Connector â†’ PostgreSQL
```

### Componentes

- **Zookeeper**: CoordenaÃ§Ã£o e gerenciamento de cluster
- **Apache Kafka**: Plataforma de streaming de dados
- **MongoDB**: Banco de dados fonte (com replicaÃ§Ã£o)
- **Debezium Connect**: ServiÃ§o de conectores Kafka
- **PostgreSQL**: Banco de dados de destino

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker
- Docker Compose

### Passos para ExecuÃ§Ã£o

1. **Clone o repositÃ³rio**
   ```bash
   git clone <url-do-repositorio>
   cd Debesium
   ```

2. **Execute o projeto**
   ```bash
   docker-compose up -d
   ```

3. **Verifique se todos os serviÃ§os estÃ£o rodando**
   ```bash
   docker-compose ps
   ```

## ğŸ“ Estrutura do Projeto

```
Debesium/
â”œâ”€â”€ docker-compose.yml          # ConfiguraÃ§Ã£o dos serviÃ§os Docker
â”œâ”€â”€ Dockerfile                  # Imagem personalizada do Debezium Connect
â”œâ”€â”€ init-connector.sh          # Script de inicializaÃ§Ã£o dos conectores
â”œâ”€â”€ mongo-connector.json       # ConfiguraÃ§Ã£o do conector MongoDB
â”œâ”€â”€ postgres-sink-connector.json # ConfiguraÃ§Ã£o do conector PostgreSQL
â””â”€â”€ readme.md                  # Este arquivo
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Conector MongoDB (Fonte)

O conector MongoDB estÃ¡ configurado para:
- Conectar ao MongoDB em `195.200.6.202:27032`
- Capturar mudanÃ§as do banco `arcos-bridge`
- Incluir todas as coleÃ§Ãµes (`.*`)
- Extrair apenas o novo estado do documento

### Conector PostgreSQL (Destino)

O conector PostgreSQL estÃ¡ configurado para:
- Conectar ao PostgreSQL em `195.200.6.202:5497`
- Banco de dados: `api_gateway_db`
- Criar automaticamente tabelas e esquemas
- Usar modo upsert com chave primÃ¡ria baseada no campo `id`

## ğŸ” Monitoramento

### Verificar Status dos Conectores

```bash
# Listar conectores
curl -X GET http://localhost:8083/connectors

# Verificar status de um conector especÃ­fico
curl -X GET http://localhost:8083/connectors/mongo-connector/status
curl -X GET http://localhost:8083/connectors/postgres-sink-connector/status
```

### Logs dos ServiÃ§os

```bash
# Logs do Kafka Connect
docker-compose logs connect

# Logs do MongoDB
docker-compose logs mongo

# Logs do Kafka
docker-compose logs kafka
```

## ğŸ› ï¸ Desenvolvimento

### Adicionar Novos Conectores

1. Crie um arquivo JSON com a configuraÃ§Ã£o do conector
2. Adicione o comando curl no script `init-connector.sh`
3. Reinicie os serviÃ§os

### Modificar ConfiguraÃ§Ãµes

- **MongoDB**: Edite `mongo-connector.json`
- **PostgreSQL**: Edite `postgres-sink-connector.json`
- **Docker**: Edite `docker-compose.yml`

## ğŸ”§ Troubleshooting

### Problemas Comuns

1. **Conectores nÃ£o iniciam**
   - Verifique se o MongoDB estÃ¡ acessÃ­vel
   - Confirme as credenciais no arquivo de configuraÃ§Ã£o
   - Verifique os logs do serviÃ§o connect

2. **Erro de conexÃ£o com banco**
   - Valide endereÃ§os IP e portas
   - Confirme usuÃ¡rio e senha
   - Verifique se o banco estÃ¡ rodando

3. **Problemas de rede**
   - Verifique se as portas nÃ£o estÃ£o em uso
   - Confirme configuraÃ§Ãµes de firewall

### Comandos Ãšteis

```bash
# Reiniciar todos os serviÃ§os
docker-compose restart

# Parar e remover containers
docker-compose down

# Remover volumes (cuidado: apaga dados)
docker-compose down -v

# Ver logs em tempo real
docker-compose logs -f
```

## ğŸ“Š Portas Utilizadas

- **8083**: Kafka Connect REST API
- **9092**: Apache Kafka
- **2181**: Zookeeper
- **27017**: MongoDB

## ğŸ”’ SeguranÃ§a

âš ï¸ **Importante**: Este projeto contÃ©m credenciais hardcoded nos arquivos de configuraÃ§Ã£o. Em ambiente de produÃ§Ã£o, considere:

- Usar variÃ¡veis de ambiente
- Implementar secrets management
- Usar Docker secrets ou Kubernetes secrets
- Criptografar senhas

## ğŸ“ LicenÃ§a

Este projeto Ã© de uso interno. Consulte a documentaÃ§Ã£o oficial do Debezium para mais informaÃ§Ãµes sobre licenciamento.

## ğŸ¤ ContribuiÃ§Ã£o

Para contribuir com o projeto:

1. FaÃ§a um fork do repositÃ³rio
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Abra um Pull Request

## ğŸ“š ReferÃªncias

- [Debezium Documentation](https://debezium.io/documentation/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [MongoDB Change Streams](https://docs.mongodb.com/manual/changeStreams/)
- [Confluent JDBC Sink Connector](https://docs.confluent.io/kafka-connect-jdbc/current/)
