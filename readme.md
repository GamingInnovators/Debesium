# Debesium - Pipeline de Dados MySQL ‚Üí Kafka

## üìã Descri√ß√£o

Este projeto implementa um pipeline completo de replica√ß√£o de dados usando **Apache Kafka**, **Debezium** e **JDBC Sink Connector**. O sistema captura mudan√ßas (Change Data Capture - CDC) do banco **MySQL Source** (`ArcosbridgeSQL`) e replica automaticamente para o banco **MySQL Sink** (`arcos_db`), garantindo sincroniza√ß√£o em tempo real entre os dois bancos de dados.

## üèóÔ∏è Arquitetura

```
MySQL Source (195.200.6.202:3310/ArcosbridgeSQL) ‚Üí Debezium ‚Üí Kafka ‚Üí JDBC Sink ‚Üí MySQL Sink (195.200.6.202:3396/arcos_db)
```

### Componentes

- **Zookeeper**: Coordena√ß√£o e gerenciamento de cluster
- **Apache Kafka**: Plataforma de streaming de dados
- **Debezium Connect**: Servi√ßo de conectores Kafka com drivers MySQL e JDBC
- **MySQL Source**: Banco de dados origem (`195.200.6.202:3310/ArcosbridgeSQL`)
- **MySQL Sink**: Banco de dados destino (`195.200.6.202:3396/arcos_db`)

## üöÄ Como Executar

### Pr√©-requisitos

- Docker Desktop
- Docker Compose
- Acesso de rede ao banco MySQL externo

### Passos para Execu√ß√£o

1. **Clone o reposit√≥rio**
   ```bash
   git clone <url-do-repositorio>
   cd Debesium
   ```

2. **Teste as conex√µes MySQL (recomendado)**
   ```bash
   # Testar MySQL Source (Linux/Mac)
   ./test-mysql-connection.sh
   ./test-mysql-sink-connection.sh
   
   # Testar MySQL Source (Windows PowerShell)
   .\test-mysql-connection.ps1
   .\test-mysql-sink-connection.ps1
   ```

3. **Construa e execute o projeto**
   ```bash
   docker-compose up -d --build
   ```

4. **Verifique se todos os servi√ßos est√£o rodando**
   ```bash
   docker-compose ps
   ```

5. **Monitore os logs**
   ```bash
   docker-compose logs -f connect
   ```

6. **Verifique os conectores**
   ```bash
   # Listar conectores
   curl http://localhost:8083/connectors
   
   # Verificar status
   curl http://localhost:8083/connectors/mysql-source-connector/status
   ```

## üìÅ Estrutura do Projeto

```
Debesium/
‚îú‚îÄ‚îÄ docker-compose.yml               # Configura√ß√£o dos servi√ßos Docker
‚îú‚îÄ‚îÄ Dockerfile                       # Imagem personalizada com drivers MySQL
‚îú‚îÄ‚îÄ init-connector.sh               # Script de inicializa√ß√£o dos conectores
‚îú‚îÄ‚îÄ mysql-source-connector.json     # Configura√ß√£o do conector MySQL Source
‚îú‚îÄ‚îÄ mysql-sink-connector.json       # Configura√ß√£o do conector MySQL Sink
‚îú‚îÄ‚îÄ test-mysql-connection.sh        # Teste conex√£o MySQL Source (Linux/Mac)
‚îú‚îÄ‚îÄ test-mysql-connection.ps1       # Teste conex√£o MySQL Source (Windows)
‚îú‚îÄ‚îÄ test-mysql-sink-connection.sh   # Teste conex√£o MySQL Sink (Linux/Mac)
‚îú‚îÄ‚îÄ test-mysql-sink-connection.ps1  # Teste conex√£o MySQL Sink (Windows)
‚îú‚îÄ‚îÄ monitor.sh                      # Script de monitoramento
‚îú‚îÄ‚îÄ swagger.yml                     # Documenta√ß√£o OpenAPI da API REST
‚îú‚îÄ‚îÄ swagger-ui.html                 # Interface web para visualizar a API
‚îú‚îÄ‚îÄ API-README.md                   # Guia de uso da documenta√ß√£o da API
‚îú‚îÄ‚îÄ Kafka-Connect-API.postman_collection.json # Collection Postman completa
‚îú‚îÄ‚îÄ Debesium-Environment.postman_environment.json # Environment Postman
‚îú‚îÄ‚îÄ POSTMAN-COLLECTION-GUIDE.md    # Guia de uso da collection Postman
‚îî‚îÄ‚îÄ readme.md                       # Este arquivo
```

## üìö Documenta√ß√£o da API

O projeto inclui documenta√ß√£o completa da API REST do Kafka Connect:

- **`swagger.yml`** - Especifica√ß√£o OpenAPI 3.0.3 completa
- **`swagger-ui.html`** - Interface web interativa (requer servidor HTTP)
- **`swagger-ui-inline.html`** - Interface web que funciona diretamente no navegador
- **`API-README.md`** - Guia detalhado de uso da API

### üåê Como Usar a Documenta√ß√£o da API

1. **Visualiza√ß√£o Local (Recomendada)**: Abra o arquivo `swagger-ui-inline.html` no navegador
   - ‚úÖ Funciona diretamente sem problemas de CORS
   - Simples: clique duas vezes no arquivo ou use `start swagger-ui-inline.html`

2. **Visualiza√ß√£o com servidor HTTP**: Use `swagger-ui.html` servindo atrav√©s de um servidor local
   - Exemplo: `python -m http.server 8000` e acesse `http://localhost:8000/swagger-ui.html`

3. **Online**: Cole o conte√∫do de `swagger.yml` em [editor.swagger.io](https://editor.swagger.io)

4. **Endpoints Principais**:
   - `GET /connectors` - Listar conectores
   - `POST /connectors` - Criar conector
   - `GET /connectors/{name}/status` - Status do conector
   - `DELETE /connectors/{name}` - Remover conector
   - `PUT /connectors/{name}/pause` - Pausar conector
   - `PUT /connectors/{name}/resume` - Resumir conector

üí° **Nota**: Se voc√™ encontrou o erro "Failed to load API definition" no `swagger-ui.html`, use o arquivo `swagger-ui-inline.html` que foi criado especificamente para resolver problemas de CORS quando arquivos s√£o abertos diretamente no navegador.

### üìã Exemplos de Uso da API

```bash
# Listar conectores
curl -X GET http://localhost:8083/connectors

# Verificar status
curl -X GET http://localhost:8083/connectors/mysql-source-connector/status

# Pausar conector
curl -X PUT http://localhost:8083/connectors/mysql-source-connector/pause

# Reiniciar conector
curl -X POST http://localhost:8083/connectors/mysql-source-connector/restart
```

### üì¨ **Collection Postman**

Para facilitar o uso da API, inclu√≠mos uma collection completa do Postman:

- **`Kafka-Connect-API.postman_collection.json`** - Collection com todos os endpoints organizados
- **`Debesium-Environment.postman_environment.json`** - Environment com vari√°veis pr√©-configuradas
- **`POSTMAN-COLLECTION-GUIDE.md`** - Guia detalhado de importa√ß√£o e uso

#### üöÄ **Como Usar**
1. **Importe** os arquivos no Postman (Import ‚Üí Upload Files)
2. **Ative** o environment "Debesium - Local Environment"
3. **Execute** os requests organizados por categoria:
   - üîß System Info
   - üìã Connector Management
   - üìä Status & Monitoring
   - üéõÔ∏è Connector Control
   - ‚öôÔ∏è Task Management
   - üß™ Quick Tests

#### üéØ **Workflows Prontos**
- **Setup Inicial**: Health Check ‚Üí List Connectors ‚Üí Create Connectors
- **Monitoramento**: Status checks de ambos os conectores
- **Troubleshooting**: Restart connectors, verificar tasks
- **Manuten√ß√£o**: Pause/Resume connectors

## ‚öôÔ∏è Configura√ß√£o

### Conector MySQL (Source)

O conector MySQL est√° configurado para:
- **Servidor**: `195.200.6.202:3310`
- **Banco**: `ArcosbridgeSQL`
- **Usu√°rio**: `root`
- **Senha**: `6x{u!bl}N2x46W7@@@`
- **Modo**: Snapshot inicial + captura cont√≠nua
- **Tabelas**: Todas as tabelas do banco `ArcosbridgeSQL`
- **T√≥pico base**: `dbserver1`

### T√≥picos Kafka Gerados

Os t√≥picos ser√£o criados automaticamente no formato:
```
dbserver1.ArcosbridgeSQL.<nome_da_tabela>
```

## üîç Monitoramento

### Verificar Status dos Conectores

```bash
# Listar conectores
curl http://localhost:8083/connectors

# Verificar status espec√≠fico
curl http://localhost:8083/connectors/mysql-source-connector/status

# Verificar configura√ß√£o
curl http://localhost:8083/connectors/mysql-source-connector/config

# Verificar t√≥picos Kafka
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list
```

### Logs dos Servi√ßos

```bash
# Logs do Kafka Connect
docker-compose logs connect

# Logs do Kafka
docker-compose logs kafka

# Logs em tempo real
docker-compose logs -f connect
```

### Consumir Mensagens de um T√≥pico

```bash
# Exemplo: consumir mensagens de uma tabela espec√≠fica
docker-compose exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic dbserver1.ArcosbridgeSQL.sua_tabela \
  --from-beginning \
  --property print.key=true
```

## üõ†Ô∏è Desenvolvimento

### Reiniciar Conectores

```bash
# Reiniciar conector espec√≠fico
curl -X POST http://localhost:8083/connectors/mysql-source-connector/restart

# Pausar conector
curl -X PUT http://localhost:8083/connectors/mysql-source-connector/pause

# Retomar conector
curl -X PUT http://localhost:8083/connectors/mysql-source-connector/resume

# Deletar conector
curl -X DELETE http://localhost:8083/connectors/mysql-source-connector
```

### Modificar Configura√ß√µes

1. **MySQL**: Edite `mysql-source-connector.json`
2. **Reconstruir**: `docker-compose down && docker-compose up -d --build`

## üîß Troubleshooting

### Problemas Comuns

1. **Conector n√£o inicia**
   - Verifique conectividade com o banco MySQL externo
   - Confirme credenciais no arquivo `mysql-source-connector.json`
   - Verifique logs: `docker-compose logs connect`

2. **Erro de conex√£o MySQL**
   - Execute: `./test-mysql-connection.sh` ou `.\test-mysql-connection.ps1`
   - Verifique se o MySQL est√° rodando na porta 3310
   - Confirme usu√°rio e senha
   - Verifique se o banco `ArcosbridgeSQL` existe

3. **Erro "binlog not enabled"**
   - O MySQL precisa ter binary logging habilitado
   - Verifique: `SHOW VARIABLES LIKE 'log_bin';`
   - Configure: `log-bin=mysql-bin` no my.cnf

4. **Erro 404 no MySQL Connector (CORRIGIDO)**
   - ‚úÖ **Problema resolvido**: O MySQL Connector mudou de localiza√ß√£o no Maven Central
   - **Antigo**: `mysql:mysql-connector-java` (n√£o funciona mais)
   - **Novo**: `com.mysql:mysql-connector-j` (atualizado no Dockerfile)
   - Dockerfile corrigido para usar a nova URL

5. **Problemas de rede**
   - Verifique firewall e portas
   - Confirme se os IPs 195.200.6.202:3310 e 3396 est√£o acess√≠veis

### Comandos √öteis

```bash
# Reiniciar todos os servi√ßos
docker-compose restart

# Parar e remover containers
docker-compose down

# Reconstruir imagens
docker-compose build --no-cache

# Ver logs espec√≠ficos
docker-compose logs -f connect

# Verificar sa√∫de dos servi√ßos
docker-compose ps

# Testar conectividade
telnet 195.200.6.202 3310
```

## üìä Portas Utilizadas

- **8083**: Kafka Connect REST API
- **9092**: Apache Kafka
- **2181**: Zookeeper
- **3310**: MySQL Externo

## üîí Seguran√ßa

‚ö†Ô∏è **Importante**: Este projeto cont√©m credenciais hardcoded nos arquivos de configura√ß√£o. Em ambiente de produ√ß√£o, considere:

- Usar vari√°veis de ambiente para credenciais
- Implementar SSL/TLS para conex√µes
- Usar secrets management (Docker Secrets, Kubernetes Secrets)
- Configurar rede isolada para bancos de dados

## üìù Notas Importantes

- O MySQL precisa ter binary logging habilitado para CDC
- O usu√°rio MySQL precisa ter privil√©gios de REPLICATION
- As tabelas precisam ter PRIMARY KEY para funcionar corretamente
- O snapshot inicial pode demorar dependendo do tamanho das tabelas

## üéØ Pr√≥ximos Passos

Ap√≥s configurar o pipeline, voc√™ pode:

1. **Criar consumidores** para processar os dados do Kafka
2. **Implementar transforma√ß√µes** usando Kafka Streams
3. **Configurar conectores de destino** (ElasticSearch, S3, etc.)
4. **Adicionar monitoramento** com Prometheus/Grafana
5. **Implementar schema registry** para controle de schemas
